<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>
        button {
            font-size: 20px;
        }

        .container {
            display: flex;
        }
        .container > div {
            width: 100%;
            padding: 10px;
        }
        canvas {
            border: 1px solid black;
            width: 100%;
            height: 128px;
        }
        video {
            width: 100%;
        }

    </style>
</head>
<body>

<button onclick="capture()">Capture</button>

<hr>

<div class="container">
    <div>
        Channels:
        <br/>
        Left:<br/>
        <canvas id="left"></canvas>

        <hr/>
        Right: <br/>
        <canvas id="right"></canvas>
    </div>
    <div>
        Output:
        <br />
        <video controls id="output"></video>
    </div>
</div>

<script>

    const output = document.getElementById('output')
    const leftCanvas = document.getElementById("left");
    const rightCanvas = document.getElementById("right");
    const leftCtx = leftCanvas.getContext("2d");
    const rightCtx = rightCanvas.getContext("2d");

    capture = async () => {
        const stream = await navigator.mediaDevices.getDisplayMedia({audio: true, video: true})
        output.srcObject = stream
        output.play()
        analyse(stream)
    }

    analyse = (stream) => {
        console.log('analyse stream', stream);
        console.log('settings', stream.getTracks()[0].getSettings());
        window.stream = stream;

        const audioContext = new AudioContext();

        const input = audioContext.createMediaStreamSource(stream);
        const splitter = audioContext.createChannelSplitter(2),
            lAnalyser = audioContext.createAnalyser(),
            rAnalyser = audioContext.createAnalyser();
        input.connect(splitter);
        splitter.connect(lAnalyser, 0, 0);
        splitter.connect(rAnalyser, 1, 0);
        const lArray = new Uint8Array(lAnalyser.frequencyBinCount),
            rArray = new Uint8Array(rAnalyser.frequencyBinCount);
        updateAnalyser();

        function updateAnalyser() {
            requestAnimationFrame(updateAnalyser);
            lAnalyser.getByteFrequencyData(lArray);
            rAnalyser.getByteFrequencyData(rArray);
            draw(lArray, rArray);
        }
    }

    const draw = (left, right) => {

        leftCtx.clearRect(0, 0, leftCanvas.width, leftCanvas.height);
        rightCtx.clearRect(0, 0, rightCanvas.width, rightCanvas.height);

        leftCtx.beginPath();
        leftCtx.strokeStyle = 'blue';
        Object.values(left).forEach((v, index) => {
            leftCtx.lineTo(index + 1, 128 - Math.floor(v / 2));
        })
        leftCtx.stroke();

        rightCtx.beginPath();
        rightCtx.strokeStyle = 'blue';
        Object.values(right).forEach((v, index) => {
            rightCtx.lineTo(index + 1, 128 - Math.floor(v / 2));
        })
        rightCtx.stroke();

    }

    pcTest = async (sourceType, sdpChanges) => {
        const pc1 = new RTCPeerConnection();
        const pc2 = new RTCPeerConnection();
        let onConnected = () => {
        }

        pc1.addEventListener('connectionstatechange', () => {
            console.log('pc1.connectionState', pc1.connectionState);
            if (pc1.connectionState === "connected") {
                onConnected();
            }
        });
        pc1.addEventListener('signalingstatechange', () => {
            console.log('pc1.signalingState', pc1.signalingState);
        });
        pc2.addEventListener('connectionstatechange', () => {
            console.log('pc2.connectionState', pc2.connectionState);
        });
        pc2.addEventListener('signalingstatechange', () => {
            console.log('pc2.signalingState', pc2.signalingState);
        });

        pc1.addEventListener('icecandidate', (c) => {
            pc2.addIceCandidate(c.candidate);
        })
        pc2.addEventListener('icecandidate', (c) => {
            pc1.addIceCandidate(c.candidate);
        });

        pc2.addEventListener('track', (e) => {
            playStream(e.streams[0]);
            analyse(e.streams[0]);
        })

        let stream = undefined;
        if (sourceType === 'mic-mono' || sourceType === 'mic-stereo') {
            stream = await getMic(sourceType === 'mic-mono' ? 1 : 2);
        } else {
            const streamWrapper = await getLocalStream(sourceType, true)
            stream = streamWrapper.stream
            onConnected = () => streamWrapper.play();
        }
        console.log(stream.getAudioTracks());
        pc1.addTrack(stream.getAudioTracks()[0], stream);
        const pc1Offer = await pc1.createOffer();

        if (sdpChanges) {
            pc1Offer.sdp = pc1Offer.sdp.replace("useinbandfec=1", "useinbandfec=1; stereo=1");
        }
        console.log('pc1Offer', pc1Offer);

        await pc1.setLocalDescription(pc1Offer);

        await pc2.setRemoteDescription(pc1Offer);
        const pc2Answer = await pc2.createAnswer();

        if (sdpChanges) {
            pc2Answer.sdp = pc2Answer.sdp.replace("useinbandfec=1", "useinbandfec=1; stereo=1");
        }

        console.log('pc2Answer', pc2Answer);
        await pc2.setLocalDescription(pc2Answer);

        await pc1.setRemoteDescription(pc2Answer);

    }

</script>
</body>
</html>
